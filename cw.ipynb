{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Regularization and Sparse Regression\n",
    "\n",
    "### Spring 2022, Week 6\n",
    "<hr>\n",
    "\n",
    "Objectives:\n",
    "-  Regularize complex linear models\n",
    "-  Evaluate performance of regularized models based on Cross-Validation\n",
    "-  Discuss the benefits and drawbacks of these methods\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr22/week6_sparseregression\n",
    "!mkdir ./data\n",
    "!cp week6_sparseregression/data/* ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (5,5)\n",
    "COLORS= [\"#008080\",\"#CA562C\"]\n",
    "\n",
    "sns.set(font_scale=1.5, rc={'figure.figsize':FIG_SIZE}) \n",
    "sns.set_style(\"whitegrid\",  {'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
    "plt.rc(\"axes.spines\", top=False, right=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the data from last week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/data.csv\")\n",
    "def get_numerical(df):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    num_df = df.select_dtypes(include=numerics)\n",
    "    return num_df\n",
    "    \n",
    "num_dataset = get_numerical(dataset)\n",
    "num_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are going to do the same thing we did in the lecture on this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cross_validation(model, X, y, k=5):\n",
    "    scores = cross_validate(model, X, y, cv=k,\n",
    "                            scoring=('r2', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    temp_model = model.fit(X, y)\n",
    "    non_zero = np.count_nonzero(temp_model.coef_)\n",
    "    return np.mean(scores['train_r2']),np.mean(scores['test_r2']), non_zero\n",
    "\n",
    "\n",
    "def parity_plot(true, pred, r_squared=None, title='', alpha=None, color=None, hue=None):\n",
    "    \"\"\"\n",
    "    plot true vs the predicted data\n",
    "    inputs: 2 list-like (arrays) data structures\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "    if hue is not None:\n",
    "        sns.scatterplot(x=true, y=pred, hue=hue)\n",
    "    else: \n",
    "        if color is None: sns.scatterplot(x=true, y=pred)\n",
    "        else: sns.scatterplot(x=true, y=pred, alpha=alpha, color=color)\n",
    "    min_value = min(min(true), min(pred))\n",
    "    max_value = max(max(true), max(pred))\n",
    "    plt.plot([min_value, max_value],[min_value, max_value], '--', label=\"parity\")\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.xlim([min_value, max_value])\n",
    "    plt.ylim([min_value, max_value])\n",
    "    sns.despine()\n",
    "    plt.text(1.01, 0.98, r\"$R^2 = {0:.2f}$\".format(r_squared),\n",
    "         ha='left', va='top', size =LABEL_FONT,\n",
    "         transform=ax.transAxes)\n",
    "    plt.title('Parity Plot: {}'.format(title), size=TITLE_FONT)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()    \n",
    "    \n",
    "def model_selection(X,y, degrees, interactions):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    poly = PolynomialFeatures(degrees, include_bias=True)\n",
    "    # print(poly.get_feature_names_out(input_features=X_train.columns))\n",
    "    X_train = poly.fit_transform(X_train)\n",
    "    poly_features = poly.get_feature_names_out()\n",
    "    X_test = poly.fit_transform(X_test, poly_features)\n",
    "    X_train_df = pd.DataFrame(X_train, columns=poly_features)\n",
    "    X_test_df = pd.DataFrame(X_test, columns=poly_features)\n",
    "    interaction_list = [feat for feat in poly_features if len(feat.split())!=1]\n",
    "    if not interactions:\n",
    "        X_train_df = X_train_df.drop(interaction_list, axis=1)\n",
    "        X_test_df = X_test_df.drop(interaction_list, axis=1)    \n",
    "    \n",
    "    \n",
    "    X_scaler = StandardScaler().fit(X_train_df)\n",
    "    y_scaler = StandardScaler().fit(y_train.values.reshape(-1,1))\n",
    "    X_z = X_scaler.transform(X_train_df)\n",
    "    y_z = y_scaler.transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    X_test_scaler = StandardScaler().fit(X_test_df)\n",
    "    y_test_scaler = StandardScaler().fit(y_test.values.reshape(-1,1))\n",
    "    X_test_z = X_scaler.transform(X_test_df)\n",
    "    y_test_z = y_scaler.transform(y_test.values.reshape(-1,1))\n",
    "    \n",
    "    alpha_dict = {}\n",
    "    p_dict = {}\n",
    "    i = 0\n",
    "    lim = 64\n",
    "    for alpha in [0, 1e-5, 1e-3, 1e-2, 1e-1, 0.5, 1, 5]:\n",
    "        alpha_dict[str(alpha)] = {}\n",
    "        p_dict[str(alpha)] = {}\n",
    "        for ratio in [0, .1, .5, .7, .9, .95, .99, 1]:\n",
    "            i += 1\n",
    "            print(f\"fitting and CV on {i} of {lim}\")\n",
    "            model = linear_model.ElasticNet(alpha=alpha, l1_ratio=ratio) \n",
    "\n",
    "            train_r2, test_r2, non_zero = cross_validation(model, X_z, y_z)\n",
    "            alpha_dict[str(alpha)][str(ratio)] = f\"{train_r2:.4f}/{test_r2:.4f}\"\n",
    "            p_dict[str(alpha)][str(ratio)] = non_zero\n",
    "            \n",
    "    cv_df = pd.DataFrame(alpha_dict)\n",
    "    parameter_df = pd.DataFrame(p_dict)\n",
    "    cv_df.index.name = \"L1 Ratio\"\n",
    "    cv_df.style.set_caption(\"Alpha\")\n",
    "    parameter_df.index.name = \"L1 Ratio\"\n",
    "    parameter_df.style.set_caption(\"Alpha\")    \n",
    "    return cv_df, parameter_df, X_z, X_test_z, y_z, y_test_z\n",
    "\n",
    "def run():\n",
    "    features = ['Start', 'End', 'G', 'U', 'bi', 'uni', 'duplex', 'Pos1', 'Pos2', 'Pos6',\n",
    "       'Pos13', 'Pos14', 'Pos18', 'Dif_5-3', 'Content+', 'Content-', 'Cons+',\n",
    "       'Cons-', 'Cons_Sum', 'Hyb19', 'target']\n",
    "    X = num_dataset[features]\n",
    "    y = num_dataset[\"Activity\"]\n",
    "    cv_df, parameter_df, X_train, X_test, y_train, y_test = model_selection(X,y,3,True)\n",
    "    return cv_df, parameter_df, X_train, X_test, y_train, y_test \n",
    "\n",
    "cv_df, parameter_df, X_train, X_test, y_train, y_test = run()\n",
    "\n",
    "print(\"\\n\"*3)\n",
    "print(\"Columns = alpha\")\n",
    "print(\"Rows = L1_ratio\")\n",
    "print(\"R^2 from TRAIN/VALIDATION:\")\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters in each model:\")\n",
    "parameter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which hyper parameters performed the best? Let's try to use them on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(np.count_nonzero(model.coef_))\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    parity_plot(y_train.flatten(), y_train_pred.flatten(), r_squared =model.score(X_train, y_train), title=\"Training Data\", color=\"grey\", alpha=0.5)\n",
    "    parity_plot(y_test.flatten(), y_test_pred.flatten(), r_squared =model.score(X_test, y_test), title=\"Test Data\", color=\"blue\", alpha=1)\n",
    "\n",
    "\n",
    "@widgets.interact_manual(alpha=[0, 1e-5, 1e-3, 1e-2, 1e-1, 0.5, 1, 5], l1_ratio=[0, .1, .5, .7, .9, .95, .99, 1])\n",
    "def build_and_test(alpha, l1_ratio):\n",
    "    model = linear_model.ElasticNet(alpha=alpha, l1_ratio=l1_ratio) \n",
    "    test_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
